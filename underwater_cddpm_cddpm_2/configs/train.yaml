# ========== Reproducibility ==========
seed: 42

# ========== Paths ==========
paths:
  train_input: /public/home/hnust15874739861/pro/publicdata/LSUI19/Train/input
  train_gt: /public/home/hnust15874739861/pro/publicdata/LSUI19/Train/GT
  val_input: /public/home/hnust15874739861/pro/publicdata/LSUI19/Val/input
  val_gt: /public/home/hnust15874739861/pro/publicdata/LSUI19/Val/GT
  out_dir: outputs/underwater_cddpm

# ========== Data ==========
data:
  image_size: 256
  random_crop: true
  random_flip: true
  num_workers: 4

# ========== Model (Full DDPM U-Net with Attention) ==========
model:
  in_channels: 3        # x_t channels (RGB)
  cond_channels: 3      # condition channels (RGB underwater input)
  out_channels: 3       # predicted noise channels (RGB)
  model_channels: 128
  channel_mult: [1, 2, 4, 8]
  num_res_blocks: 2
  attention_resolutions: [16, 8]  # spatial sizes (e.g. 16x16 and 8x8) that use full self-attention
  num_heads: 4
  dropout: 0.1
  use_checkpoint: false  # gradient checkpointing (saves memory)
  use_scale_shift_norm: true

# ========== Diffusion ==========
diffusion:
  timesteps: 1000
  beta_schedule: linear   # linear | cosine
  beta_start: 0.0001
  beta_end: 0.02
  clip_denoised: true     # clip x0_pred to [-1, 1] during sampling
  loss_type: eps          # standard DDPM: MSE(eps_pred, eps)

# ========== Training ==========
training:
  epochs: 200
  batch_size: 32
  lr: 2.0e-4
  weight_decay: 0.0
  grad_clip: 1.0
  mixed_precision: true

  ema:
    enabled: true
    decay: 0.9999
    update_after_step: 0
    update_every: 1

# ========== Validation ==========
validation:
  interval_epochs: 1
  # How many val images to compute PSNR/SSIM on by sampling.
  # -1 means use all val images (can be slow).
  num_samples: 50

  # Sampler for metrics (ddim is much faster than full ddpm):
  sampler: ddim           # ddpm | ddim
  sample_steps: 50        # only for ddim; ddpm uses diffusion.timesteps
  eta: 0.0                # ddim noise (0.0 = deterministic)

  save_visuals: true
  visuals_max: 8

# ========== After training: generate outputs with best checkpoints ==========
sampling_after_train:
  enabled: true
  split: val              # val | train
  sampler: ddim           # ddpm | ddim
  sample_steps: 50
  eta: 0.0
